{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Technical Notebook - Knitting Pattern Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ravelry.com is a database-driven website where users can browse and download knitting and crochet patterns, track their progress on a given project, and review the patterns. \n",
    "\n",
    "It currently has a \"your pattern highlights\" recommender system. Compared to the front-and-centre recommendations that Netflix or Amazon make to their users, it's tucked away at the bottom of the patterns search page, displaying only thumbnail images of the recommended pattterns. \n",
    "\n",
    "The recommendations generated appear to be based on clicks and/or favourites, rather than a more comprehensive examination of what projects users actually work on and rate positively, having experienced making them. \n",
    "\n",
    "The aim of this project is to provide more tailored recommendations for knitting patterns to users of Ravelry.com, based on patterns they have worked on and rated already. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has all been obtained through the Ravelry.com API. Since the website does not have an app, it makes all of its content available through APIs, and at present there are 41 apps which make use of some or all of the websites functionality.\n",
    "\n",
    "The modelling features for a collaborative filtering recommender system are users, items and ratings. the model finds similarities between users based on their ratings of items, and uses these similarities to predict ratings for items for users who have not already rated them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import surprise\n",
    "from surprise.prediction_algorithms import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block pandas warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open credentials\n",
    "\n",
    "with open('C:/Users/clare/Documents/Flatiron/PatternRecommender/.secrets/creds.json') as f:\n",
    "    creds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and drop null ratings\n",
    "\n",
    "input_df = pd.read_csv('saved_100000_calls.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156206"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Should I randomly sample input_df for each run? To get more variation in recommendations and speed up run time?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was tested on the data with missing ratings removed, and then with missing ratings replaced with pattern averages. Replacing missing values with pattern averages negatively impacted the RMSE for SVD, so proceeded with the missing values dropped. \n",
    "\n",
    "Also, one series of the dataframe contained lists which converted to strings after reading from the CSV. These were converted back to lists by slicing and splitting. \n",
    "\n",
    "Lastly, the sk surprise package requires a specific version of the data to run its models, generated by passing the dataframe containing only user, item and rating (in that order) to the <code>load_from_df</code> and then <code>train_test_split</code> (for evaluation) or <code>build_full_trainset</code> (for final model) methods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_nans = input_df[['user', 'pattern_id', 'rating']].dropna(subset = ['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace Nan ratings with pattern average. note - this negatively impacts RMSE, so the dataframe with dropped Nans is used\n",
    "# for modelling\n",
    "\n",
    "df_replace_nans = input_df[['user', 'pattern_id', 'rating', 'average_rating']]\n",
    "rating_replace_nans = df_replace_nans['rating'].fillna(df_replace_nans['average_rating'])\n",
    "df_replace_nans['rating'] = rating_replace_nans\n",
    "df_replace_nans.drop(columns = 'average_rating', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of users in the original data\n",
    "\n",
    "users_list = list(df_drop_nans['user'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe with a list of applicable categories (usually only one) for each pattern\n",
    "\n",
    "# to-do: vectorize this for loop. \n",
    "\n",
    "df_pattern_ids_and_categories = input_df[['pattern_id', 'categories']]\n",
    "df_pattern_ids_and_categories = df_pattern_ids_and_categories.drop_duplicates(subset=['pattern_id'])\n",
    "df_pattern_ids_and_categories['cat_list'] = ''\n",
    "for pattern in list(df_pattern_ids_and_categories.index):\n",
    "    df_pattern_ids_and_categories['cat_list'][pattern] = [category[1:-1] for category in df_pattern_ids_and_categories['categories'][pattern][1:-1].split(', ')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data for surprise\n",
    "\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader()\n",
    "\n",
    "data_drop = Dataset.load_from_df(df_drop_nans, reader)\n",
    "data_replace = Dataset.load_from_df(df_replace_nans, reader)\n",
    "\n",
    "# train test split for model evaluation\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "drop_trainset, drop_testset = train_test_split(data_drop, test_size=0.25)\n",
    "replace_trainset, replace_testset = train_test_split(data_replace, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the KNN, Matrix Factorization, Slope One, and Co-Clustering modelling methods within the sk surprise pacage were used, and evaluated based on their RMSE on predicted ratings, using a 25% train test split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD - dropped NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6421225154646983"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, accuracy\n",
    "\n",
    "SVD_1_drop = SVD(n_factors = 40, n_epochs = 45, lr_all = 0.002, reg_all = 0.2)\n",
    "SVD_1_drop.fit(drop_trainset)\n",
    "\n",
    "accuracy.rmse(SVD_1_drop.test(drop_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD - replaced NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8804658164760572"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVD_1_replace = SVD(n_factors = 40, n_epochs = 45, lr_all = 0.002, reg_all = 0.2)\n",
    "SVD_1_replace.fit(replace_trainset)\n",
    "\n",
    "accuracy.rmse(SVD_1_replace.test(replace_testset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch on SVD - dropped NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed:   51.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2154 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 15.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3018 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3504 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed: 28.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4584 tasks      | elapsed: 31.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5178 tasks      | elapsed: 37.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5808 tasks      | elapsed: 43.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6474 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 56.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7914 tasks      | elapsed: 65.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8688 tasks      | elapsed: 72.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9498 tasks      | elapsed: 80.5min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed: 88.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': {'n_factors': 5, 'n_epochs': 40, 'lr_all': 0.002, 'reg_all': 0.2},\n",
       " 'mae': {'n_factors': 5, 'n_epochs': 45, 'lr_all': 0.004, 'reg_all': 0.2}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_factors':[5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "              'n_epochs': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50], \n",
    "              'lr_all': [0.002, 0.003, 0.004, 0.005],\n",
    "              'reg_all': [0.2, 0.3, 0.4, 0.5, 0.6]}\n",
    "\n",
    "gs_model = GridSearchCV(SVD,\n",
    "                        param_grid=param_grid,\n",
    "                        n_jobs = -1,\n",
    "                        joblib_verbose=5)\n",
    "\n",
    "gs_model.fit(data_drop)\n",
    "\n",
    "gs_model.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6416092621558532"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from GridSearch\n",
    "\n",
    "GS_SVD = SVD(n_factors = 5, n_epochs = 40, lr_all = 0.002, reg_all = 0.2)\n",
    "GS_SVD.fit(drop_trainset)\n",
    "\n",
    "predictions = GS_SVD.test(drop_testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Variable Decomposition - SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.641950083397907"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVDppmodel = SVDpp(n_factors = 15, n_epochs = 30, lr_all = 0.003, reg_all = 0.2)\n",
    "\n",
    "SVDppmodel.fit(drop_trainset)\n",
    "predictions = SVDppmodel.test(drop_testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch on SVD++ - dropped NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  9.5min\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_factors':[5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "              'n_epochs': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50], \n",
    "              'lr_all': [0.002, 0.003, 0.004, 0.005],\n",
    "              'reg_all': [0.2, 0.3, 0.4, 0.5, 0.6]}\n",
    "\n",
    "gs_model = GridSearchCV(SVDpp,\n",
    "                        param_grid=param_grid,\n",
    "                        n_jobs = -1,\n",
    "                        joblib_verbose=5)\n",
    "\n",
    "gs_model.fit(data_drop)\n",
    "\n",
    "gs_model.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Surprise Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise.prediction_algorithms import knns\n",
    "from surprise.similarities import cosine, msd, pearson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-do: Try these 7 on the data_replace?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Basic - cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.6943\n",
      "0.6943113545536386\n"
     ]
    }
   ],
   "source": [
    "sim_cos = {'name':'cosine', 'user_based':True}\n",
    "\n",
    "basic = knns.KNNBasic(min_k = 8, sim_options=sim_cos)\n",
    "basic.fit(drop_trainset)\n",
    "predictions = basic.test(drop_testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Basic - Pearson similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.6937\n",
      "0.6937224190586495\n"
     ]
    }
   ],
   "source": [
    "sim_pearson = {'name':'pearson', 'user_based':True}\n",
    "\n",
    "basic = knns.KNNBasic(min_k = 8, sim_options=sim_pearson)\n",
    "basic.fit(drop_trainset)\n",
    "predictions = basic.test(drop_testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN with Means - Pearson similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.6653\n",
      "0.6652588419819415\n"
     ]
    }
   ],
   "source": [
    "sim_pearson = {'name':'pearson', 'user_based':True}\n",
    "\n",
    "basic = knns.KNNWithMeans(min_k = 8, sim_options=sim_pearson)\n",
    "basic.fit(drop_trainset)\n",
    "predictions = basic.test(drop_testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Baseline - Pearson similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.6732\n",
      "0.673159791692249\n"
     ]
    }
   ],
   "source": [
    "sim_pearson = {'name':'pearson', 'user_based':True}\n",
    "\n",
    "knn_baseline = knns.KNNBaseline(sim_options=sim_pearson)\n",
    "knn_baseline.fit(drop_trainset)\n",
    "predictions = knn_baseline.test(drop_testset)\n",
    "print(accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slope One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7349163524043302"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Slope_One = SlopeOne()\n",
    "\n",
    "Slope_One.fit(drop_trainset)\n",
    "predictions = Slope_One.test(drop_testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7296378851524683"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocluster = CoClustering()\n",
    "\n",
    "cocluster.fit(drop_trainset)\n",
    "predictions = cocluster.test(drop_testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were tested on the ratings only for projects marked \"finished\", and then on ratings for projects of all statuses: \"finished\", \"in-progress\", \"hibernating\", and \"frogged\" $^{1}$. The SVD model achieves the lowest RMSE in either case. While the RMSE is lower where only ratings for completed projects are input, this can lead to imbalanced data, as users are more likely to rate higeher projects which they have finished. \n",
    "\n",
    "$^{1}$ \"Frogged\" refers to a project which was started and then un-knit, or ripped out. The word refers to the sound a frog makes: \"ribbit, ribbit\", or \"Rip it, rip it\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: maybe a voting classifier here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model: grid searched parameters on SVD\n",
    "            \n",
    "best_model = SVD(n_factors = 15, n_epochs = 30, lr_all = 0.003, reg_all = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1f5bd665b20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on entire dataset\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "trainset = DatasetAutoFolds.build_full_trainset(data_drop)\n",
    "\n",
    "best_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is not yet deployed to a user interface. The functions below generate ratings predictions for items that users have not yet interacted with, either by tracking a project, adding a pattern to their queue, or favouriting a pattern. \n",
    "\n",
    "Utilising only predicted ratings resulted in almost all users being recommended the same patterns: those that were highly rated in all cases. This did not achieve the type of tailored recommendations anticipated. \n",
    "\n",
    "The categories of the user's projects: i.e. sweater, soft-toy, ankle-socks are obtained using the API and only those items matching their most frequently knit categories are returned from the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a data frame of projects tracked by a given user\n",
    "\n",
    "def get_user_projects(user):\n",
    "   \n",
    "    url ='https://api.ravelry.com/projects/' + user + '/list.json?sort=completed_'\n",
    "    response = requests.get(url, auth=(creds['id'], creds['key']))\n",
    "    projects = []\n",
    "    try:\n",
    "        for project in response.json()['projects']:\n",
    "            if project['craft_name'] == 'Knitting': \n",
    "                if project['pattern_id'] != None:\n",
    "                    pattern_url ='https://api.ravelry.com/patterns.json?ids=' + str(int(project['pattern_id']))\n",
    "                    pattern_response = requests.get(pattern_url, auth=(creds['id'], creds['key']))\n",
    "                    project_tuple = (user, project['completed'], project['rating'], project['status_name'], \n",
    "                                     project['pattern_id'],\n",
    "                                     pattern_response.json()['patterns'][str(int(project['pattern_id']))]['rating_average'],\n",
    "                                     pattern_response.json()['patterns'][str(int(project['pattern_id']))]['rating_count'],\n",
    "                                     [attribute['permalink'] for attribute in pattern_response.json()['patterns'][str(int(project['pattern_id']))]['pattern_attributes']],\n",
    "                                     [category['permalink'] for category in pattern_response.json()['patterns'][str(int(project['pattern_id']))]['pattern_categories']])\n",
    "                    projects.append(project_tuple)\n",
    "        df = pd.DataFrame(projects, columns = ['user', 'completed', 'rating', 'status', 'pattern_id', 'average_rating', 'rating_count', 'attributes', 'categories'])\n",
    "            \n",
    "    except ValueError:\n",
    "        print('not a user')\n",
    "        pass\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of ongoing, frogged, or hibernated projects for a given user - only if user is already in modelling data\n",
    "\n",
    "def get_user_projects_not_finished(user):\n",
    "\n",
    "    users_projects_not_completed = requests.get('https://api.ravelry.com/projects/' + user + '/list.json', \n",
    "                                                auth=(creds['id'], creds['key']))\n",
    "\n",
    "    df = pd.DataFrame(users_projects_not_completed.json()['projects'])\n",
    "    users_projects_not_completed = list(set(df[df['status_name'] != 'Finished']['pattern_id'].dropna()))\n",
    "    \n",
    "    return users_projects_not_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of projects in a user's queue\n",
    "\n",
    "def get_user_queue(user):\n",
    "\n",
    "    users_queue = requests.get('https://api.ravelry.com/people/' + user + '/queue/list.json?page_size=100', \n",
    "                                                auth=(creds['id'], creds['key']))\n",
    "    \n",
    "    users_queue = list(set(pd.DataFrame(users_queue.json()['queued_projects'])['pattern_id'].dropna()))\n",
    "\n",
    "    return users_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of a patterns favourited by a given user\n",
    "\n",
    "def get_user_favorites(user):\n",
    "\n",
    "    users_favourites = requests.get('https://api.ravelry.com/people/' + user + '/favorites/list.json?page_size=100', \n",
    "                                                auth=(creds['id'], creds['key']))\n",
    "    \n",
    "    df = pd.DataFrame(users_favourites.json()['favorites'])\n",
    "    users_favourites = list(pd.DataFrame(list(df[df['type'] == 'pattern']['favorited']))['id'])\n",
    "    \n",
    "    return users_favourites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns patterns predicted to earn a rating of 3 or more for a given user \n",
    "\n",
    "def top_rated(user):\n",
    "    \n",
    "    # if the user is already in the data, no need to refit model\n",
    "    \n",
    "    if user in users_list:\n",
    "        \n",
    "        # make a list of patterns in modelling data, remove any the user has previously interacted with, generate \n",
    "        # predicted ratings for those patterns, output any greater than 3 to df\n",
    "        \n",
    "        patterns_list = list(input_df['pattern_id'].unique())\n",
    "    \n",
    "        predictions = []\n",
    "        \n",
    "        users_patterns = list(input_df[input_df['user'] == user]['pattern_id'])\n",
    "        users_favourites = get_user_favorites(user)\n",
    "        users_queue = get_user_queue(user)\n",
    "        users_projects_not_completed = get_user_projects_not_finished(user)\n",
    "        \n",
    "        previously_interacted = users_patterns + users_favourites + users_queue + users_projects_not_completed\n",
    "        \n",
    "        remaining_patterns = [x for x in patterns_list if x not in previously_interacted]\n",
    "\n",
    "    \n",
    "        for pattern in remaining_patterns:\n",
    "            x = best_model.predict(user, pattern)\n",
    "            predictions.append(x)\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\"user\": [prediction.uid for prediction in predictions],\n",
    "                                       \"item\": [prediction.iid for prediction in predictions],\n",
    "                                       \"estimated\" :[prediction.est for prediction in predictions]})\n",
    "    \n",
    "        predictions_df = predictions_df[predictions_df['estimated'] > 3]\n",
    "        predictions_df = predictions_df.sort_values('estimated', ascending = False)\n",
    "    \n",
    "        return predictions_df\n",
    "    \n",
    "    elif user not in users_list:\n",
    "        \n",
    "        # get user data to match modelling data, transform to match, and refit model with that user included. \n",
    "        \n",
    "        try: \n",
    "            \n",
    "            new_user_ratings = get_user_projects(user)\n",
    "            new_user_input_df = input_df.append(new_user_ratings).reset_index().drop(columns = 'index')\n",
    "        \n",
    "            df_drop_nans_new_user = new_user_input_df[['user', 'pattern_id', 'rating']].dropna(subset = ['rating'])\n",
    "        \n",
    "            reader = Reader()\n",
    "            data_drop_new_user = Dataset.load_from_df(df_drop_nans_new_user, reader)\n",
    "            trainset_new_user = DatasetAutoFolds.build_full_trainset(data_drop_new_user)\n",
    "        \n",
    "            best_model.fit(trainset_new_user)\n",
    "    \n",
    "            # make a list of patterns in modelling data, remove any the user has previously interacted with, generate \n",
    "            # predicted ratings for those patterns, output any greater than 3 to df\n",
    "    \n",
    "            patterns_list = list(new_user_input_df['pattern_id'].unique())\n",
    "            predictions = []\n",
    "        \n",
    "            users_patterns = list(new_user_input_df[new_user_input_df['user'] == user]['pattern_id'])\n",
    "            users_favourites = get_user_favorites(user)\n",
    "            users_queue = get_user_queue(user)\n",
    "            users_projects_not_completed = list(set(new_user_ratings[new_user_ratings['status'] != 'Finished']['pattern_id'].dropna()))\n",
    "        \n",
    "            previously_interacted = users_patterns + users_favourites + users_queue + users_projects_not_completed\n",
    "        \n",
    "            remaining_patterns = [pattern for pattern in patterns_list if pattern not in previously_interacted]\n",
    "    \n",
    "            for pattern in remaining_patterns:\n",
    "                x = best_model.predict(user, pattern)\n",
    "                predictions.append(x)\n",
    "                \n",
    "            predictions_df = pd.DataFrame({\"user\": [prediction.uid for prediction in predictions],\n",
    "                                           \"item\": [prediction.iid for prediction in predictions],\n",
    "                                           \"estimated\": [prediction.est for prediction in predictions]})\n",
    "    \n",
    "            predictions_df = predictions_df[predictions_df['estimated'] > 3]\n",
    "            predictions_df = predictions_df.sort_values('estimated', ascending = False)\n",
    "            \n",
    "            return predictions_df\n",
    "        \n",
    "        except ValueError:\n",
    "            print('not a user')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a list of the users most frequently knitted types of patterns (i.e. scarves, toys, cardigans...)\n",
    "\n",
    "def user_fave_categories(user):\n",
    "\n",
    "    user_projects = get_user_projects(user)\n",
    "\n",
    "    user_projects['cat'] = ''\n",
    "    for project in range(0,len(user_projects)):\n",
    "        user_projects['cat'][project] = user_projects['categories'][project].sort()\n",
    "        for category in range(0,len(user_projects['categories'][project])):\n",
    "            user_projects['cat'][project] = user_projects['categories'][project][category]\n",
    "        \n",
    "    df_count_categories = user_projects.groupby('cat').count().sort_values('user', ascending = False)\n",
    "    df_count_categories = df_count_categories.reset_index()[['cat', 'user']]\n",
    "    if len(df_count_categories) <= 5:\n",
    "        favorite_categories = list(df_count_categories['cat'])\n",
    "    elif len(df_count_categories) <=20:\n",
    "        favorite_categories = list(df_count_categories.head(5)['cat'])\n",
    "    elif len(df_count_categories) > 20:\n",
    "        favorite_categories = list(df_count_categories.head(math.ceil(len(df_count_categories)/5))['cat'])\n",
    "\n",
    "    return favorite_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user):\n",
    "    \n",
    "    try: \n",
    "\n",
    "        fave_categories = user_fave_categories(user)\n",
    "\n",
    "        # merge df of user recommendations with input df containing item categories\n",
    "        \n",
    "        recs = top_rated(user)\n",
    "        recs['pattern_id'] = recs['item']\n",
    "        result = pd.merge(df_pattern_ids_and_categories, recs, how=\"inner\", on=[\"pattern_id\"])\n",
    "        result\n",
    "        \n",
    "        # drop any recommendations not corresponding to users top categories\n",
    "        \n",
    "        result['favourites_list'] = ''\n",
    "        for rec in list(result.index):\n",
    "            if len(list(set(result['cat_list'][rec]).intersection(set(fave_categories)))) != 0:\n",
    "                result['favourites_list'][rec] = 1\n",
    "            else: \n",
    "                result['favourites_list'][rec] = 0\n",
    "                \n",
    "        result = result[result['favourites_list'] != 0]\n",
    "        result = result.sort_values('estimated', ascending = False).head(15)\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # get pattern name and generate url\n",
    "    \n",
    "        for pattern in list(result['item']):\n",
    "        \n",
    "            pattern_url ='https://api.ravelry.com/patterns.json?ids=' + str(pattern)\n",
    "            pattern_response = requests.get(pattern_url, auth=(creds['id'], creds['key']))\n",
    "            recommendations.append('ravelry.com/patterns/library/' + str(pattern_response.json()['patterns'][str(pattern)]['permalink']))\n",
    "    \n",
    "        return recommendations\n",
    "    \n",
    "    except ValueError: \n",
    "        print('The user you have entered is not signed up to Ravelry.com')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ravelry.com/patterns/library/pussyhat-4-gauges-in-the-round',\n",
       " 'ravelry.com/patterns/library/clapo-ktus',\n",
       " 'ravelry.com/patterns/library/tiong-bahru',\n",
       " 'ravelry.com/patterns/library/getting-warmer',\n",
       " 'ravelry.com/patterns/library/tulips-a-colorful-cardigan-for-baby',\n",
       " 'ravelry.com/patterns/library/blooming-stitch-shawl',\n",
       " 'ravelry.com/patterns/library/hootin-owlie-hat',\n",
       " 'ravelry.com/patterns/library/lake-reed',\n",
       " 'ravelry.com/patterns/library/lady-eleanor-entrelac-stole',\n",
       " 'ravelry.com/patterns/library/feather--fan-any-yarn-shawl-or-scarf-shawlette',\n",
       " 'ravelry.com/patterns/library/anders',\n",
       " 'ravelry.com/patterns/library/aeolian-shawl',\n",
       " 'ravelry.com/patterns/library/ferocious-briocheous',\n",
       " 'ravelry.com/patterns/library/beyond-puerperium',\n",
       " 'ravelry.com/patterns/library/little-scallops']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('elfsmirk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ravelry.com/patterns/library/pussyhat-4-gauges-in-the-round',\n",
       " 'ravelry.com/patterns/library/tiong-bahru',\n",
       " 'ravelry.com/patterns/library/nubbins-dishcloth',\n",
       " 'ravelry.com/patterns/library/getting-warmer',\n",
       " 'ravelry.com/patterns/library/clapo-ktus',\n",
       " 'ravelry.com/patterns/library/lady-eleanor-entrelac-stole',\n",
       " 'ravelry.com/patterns/library/the-almost-lost-washcloth',\n",
       " 'ravelry.com/patterns/library/hootin-owlie-hat',\n",
       " 'ravelry.com/patterns/library/198-37-clean--colourful',\n",
       " 'ravelry.com/patterns/library/aeolian-shawl',\n",
       " 'ravelry.com/patterns/library/ferocious-briocheous',\n",
       " 'ravelry.com/patterns/library/lake-reed',\n",
       " 'ravelry.com/patterns/library/paris-in-berlin',\n",
       " 'ravelry.com/patterns/library/musselburgh',\n",
       " 'ravelry.com/patterns/library/hipster-shawl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('scarahliz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ravelry.com/patterns/library/pussyhat-4-gauges-in-the-round',\n",
       " 'ravelry.com/patterns/library/tiong-bahru',\n",
       " 'ravelry.com/patterns/library/clapo-ktus',\n",
       " 'ravelry.com/patterns/library/getting-warmer',\n",
       " 'ravelry.com/patterns/library/lake-reed',\n",
       " 'ravelry.com/patterns/library/blooming-stitch-shawl',\n",
       " 'ravelry.com/patterns/library/tulips-a-colorful-cardigan-for-baby',\n",
       " 'ravelry.com/patterns/library/hootin-owlie-hat',\n",
       " 'ravelry.com/patterns/library/windward-2',\n",
       " 'ravelry.com/patterns/library/basic-sock-pattern-in-8-sizes',\n",
       " 'ravelry.com/patterns/library/aeolian-shawl',\n",
       " 'ravelry.com/patterns/library/musselburgh',\n",
       " 'ravelry.com/patterns/library/dropping-madness-socks',\n",
       " 'ravelry.com/patterns/library/revontuli--huivi-northern-lights',\n",
       " 'ravelry.com/patterns/library/very-warm-hat']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('jacquieblackman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ravelry.com/patterns/library/getting-warmer',\n",
       " 'ravelry.com/patterns/library/tiong-bahru',\n",
       " 'ravelry.com/patterns/library/lady-eleanor-entrelac-stole',\n",
       " 'ravelry.com/patterns/library/tulips-a-colorful-cardigan-for-baby',\n",
       " 'ravelry.com/patterns/library/aeolian-shawl',\n",
       " 'ravelry.com/patterns/library/blooming-stitch-shawl',\n",
       " 'ravelry.com/patterns/library/ferocious-briocheous',\n",
       " 'ravelry.com/patterns/library/weeding-sleeve',\n",
       " 'ravelry.com/patterns/library/revontuli--huivi-northern-lights',\n",
       " 'ravelry.com/patterns/library/paris-in-berlin',\n",
       " 'ravelry.com/patterns/library/springtime-in-hollis',\n",
       " 'ravelry.com/patterns/library/laminaria',\n",
       " 'ravelry.com/patterns/library/sizzle-pop',\n",
       " 'ravelry.com/patterns/library/forest-park-cowl',\n",
       " 'ravelry.com/patterns/library/spiral-yoke-adult']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('dasjabbadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
